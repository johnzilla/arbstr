---
phase: 08-stream-request-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/proxy/types.rs
  - src/proxy/handlers.rs
  - src/storage/logging.rs
  - tests/stream_options.rs
autonomous: true
must_haves:
  truths:
    - "When arbstr forwards a streaming request, the upstream JSON payload includes stream_options with include_usage: true"
    - "Non-streaming requests have no stream_options field in the upstream payload"
    - "Client-provided stream_options are merged, not overwritten (include_usage added only if missing)"
    - "A database UPDATE can write input_tokens, output_tokens, and cost_sats to an existing request log row by correlation_id"
    - "Existing tests pass unchanged -- all additions are backward-compatible Option types"
  artifacts:
    - path: "src/proxy/types.rs"
      provides: "StreamOptions struct and stream_options field on ChatCompletionRequest"
      contains: "pub struct StreamOptions"
    - path: "src/proxy/handlers.rs"
      provides: "ensure_stream_options call at send time for streaming requests"
      contains: "ensure_stream_options"
    - path: "src/storage/logging.rs"
      provides: "update_usage and spawn_usage_update functions"
      exports: ["update_usage", "spawn_usage_update"]
    - path: "tests/stream_options.rs"
      provides: "Integration test proving stream_options appears in upstream request body"
      min_lines: 30
  key_links:
    - from: "src/proxy/handlers.rs"
      to: "src/proxy/types.rs"
      via: "ensure_stream_options function"
      pattern: "ensure_stream_options.*&mut.*request"
    - from: "src/storage/logging.rs"
      to: "sqlx"
      via: "UPDATE requests SET query"
      pattern: "UPDATE requests SET.*WHERE correlation_id"
---

<objective>
Add stream_options injection and post-stream database UPDATE for Phase 8: Stream Request Foundation.

Purpose: Enable providers to send token usage data in streaming responses (via stream_options injection), and provide a database UPDATE path so Phase 10 can write extracted usage back to the request log after a stream completes.

Output: Modified types.rs, handlers.rs, logging.rs, and new integration test file.
</objective>

<execution_context>
@/home/john/.claude/get-shit-done/workflows/execute-plan.md
@/home/john/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/proxy/types.rs
@src/proxy/handlers.rs
@src/storage/logging.rs
@tests/env_expansion.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add StreamOptions type and inject into streaming requests at send time</name>
  <files>src/proxy/types.rs, src/proxy/handlers.rs, tests/stream_options.rs</files>
  <action>
**In `src/proxy/types.rs`:**

1. Add a `StreamOptions` struct after the existing `StopSequence` enum:
   ```rust
   /// Options controlling streaming response behavior (OpenAI-compatible).
   #[derive(Debug, Clone, Deserialize, Serialize)]
   pub struct StreamOptions {
       /// When true, the final streaming chunk includes a usage object.
       #[serde(skip_serializing_if = "Option::is_none")]
       pub include_usage: Option<bool>,
   }
   ```

2. Add a `stream_options` field to `ChatCompletionRequest` after the existing `stream` field:
   ```rust
   #[serde(skip_serializing_if = "Option::is_none")]
   pub stream_options: Option<StreamOptions>,
   ```

3. Add a standalone function `ensure_stream_options` on or near the `ChatCompletionRequest` impl block. This function merges rather than overwrites per user decision:
   ```rust
   /// Ensure stream_options includes `include_usage: true` for streaming requests.
   ///
   /// Merges with any existing client-provided stream_options rather than overwriting.
   /// Only adds `include_usage: true` if the field is not already set.
   pub fn ensure_stream_options(request: &mut ChatCompletionRequest) {
       match &mut request.stream_options {
           Some(opts) => {
               if opts.include_usage.is_none() {
                   opts.include_usage = Some(true);
               }
           }
           None => {
               request.stream_options = Some(StreamOptions {
                   include_usage: Some(true),
               });
           }
       }
   }
   ```

4. Add unit tests in the existing `#[cfg(test)]` block of types.rs (if one exists) or inline at the bottom:
   - Test that `ensure_stream_options` sets `include_usage: true` when stream_options is None
   - Test that it sets `include_usage: true` when stream_options exists but include_usage is None
   - Test that it preserves existing `include_usage: false` (does NOT override -- per merge strategy, only sets when is_none)
   - Wait -- re-read the decision: "preserve their settings and only add `include_usage: true` if missing". The `is_none()` check means if client explicitly set `include_usage: false`, we leave it. This is correct per merge semantics.
   - Test that serialization of a request without stream_options does NOT include the field (skip_serializing_if works)

**In `src/proxy/handlers.rs`:**

5. In the `send_to_provider` function, before the `.json(request)` call (around line 497), add stream_options injection for streaming requests only. Since `request` is `&ChatCompletionRequest` (immutable), clone it for mutation:
   ```rust
   // Inject stream_options for streaming requests (per user decision: at send time)
   let request_body = if is_streaming {
       let mut modified = request.clone();
       crate::proxy::types::ensure_stream_options(&mut modified);
       modified
   } else {
       request.clone()
   };
   ```
   Then change `.json(request)` to `.json(&request_body)`.

   Note: The clone cost is negligible compared to the HTTP round-trip (per research common pitfalls).

6. Import `ensure_stream_options` is not needed since we're calling it via full path. Alternatively, add `use super::types::ensure_stream_options;` at the top of handlers.rs and call directly. Choose whichever is cleaner -- discretion area.

**In `tests/stream_options.rs`:**

7. Create a new integration test file following the pattern in `tests/env_expansion.rs`. This test:
   - Starts a wiremock `MockServer`
   - Registers a mock that captures the request body and responds with a streaming SSE response (minimal: just `data: [DONE]\n\n`)
   - Creates a minimal arbstr config pointing at the mock server
   - Starts the arbstr server (or calls `send_to_provider` directly if easier)
   - Sends a streaming request (`stream: true`) to arbstr
   - Asserts the captured upstream request body contains `"stream_options":{"include_usage":true}`
   - Sends a non-streaming request (`stream: false` or absent) and asserts the upstream body does NOT contain `"stream_options"`

   If a full integration test with server startup is too heavy, a simpler approach: unit-test the serialization by creating a `ChatCompletionRequest` with `stream: true`, calling `ensure_stream_options`, serializing to JSON, and asserting the field is present. Then serialize one without calling ensure_stream_options and assert the field is absent. This can go in types.rs tests instead. Use judgment for the best balance of coverage and simplicity.
  </action>
  <verify>
Run `cargo test` -- all existing tests pass plus new stream_options tests pass. Run `cargo clippy -- -D warnings` -- no warnings.
  </verify>
  <done>
StreamOptions struct exists in types.rs. ChatCompletionRequest has stream_options field. ensure_stream_options function merges include_usage. send_to_provider injects stream_options when is_streaming is true. Non-streaming requests are unmodified. At least 3 unit tests cover injection logic (None, Some without include_usage, Some with include_usage already set).
  </done>
</task>

<task type="auto">
  <name>Task 2: Add post-stream database UPDATE for token counts and cost</name>
  <files>src/storage/logging.rs</files>
  <action>
**In `src/storage/logging.rs`:**

1. Add an `update_usage` async function after the existing `RequestLog::insert` method:
   ```rust
   /// Update an existing request log entry with post-stream usage data.
   ///
   /// Writes input_tokens, output_tokens, and cost_sats to the row matching
   /// the given correlation_id. Returns the number of rows affected.
   ///
   /// Per user decision: only updates token/cost columns. Latency stays as
   /// TTFB from INSERT (Phase 10 handles full-stream latency).
   pub async fn update_usage(
       pool: &SqlitePool,
       correlation_id: &str,
       input_tokens: Option<u32>,
       output_tokens: Option<u32>,
       cost_sats: Option<f64>,
   ) -> Result<u64, sqlx::Error> {
       let result = sqlx::query(
           "UPDATE requests SET input_tokens = ?, output_tokens = ?, cost_sats = ? WHERE correlation_id = ?"
       )
       .bind(input_tokens.map(|v| v as i64))
       .bind(output_tokens.map(|v| v as i64))
       .bind(cost_sats)
       .bind(correlation_id)
       .execute(pool)
       .await?;
       Ok(result.rows_affected())
   }
   ```

2. Add a `spawn_usage_update` fire-and-forget wrapper following the exact pattern of `spawn_log_write`:
   ```rust
   /// Spawn a fire-and-forget database usage update.
   ///
   /// Warns if the update affects zero rows (row not found) or fails.
   /// Logs at debug level on success.
   pub fn spawn_usage_update(
       pool: &SqlitePool,
       correlation_id: String,
       input_tokens: Option<u32>,
       output_tokens: Option<u32>,
       cost_sats: Option<f64>,
   ) {
       let pool = pool.clone();
       tokio::spawn(async move {
           match update_usage(&pool, &correlation_id, input_tokens, output_tokens, cost_sats).await {
               Ok(0) => {
                   tracing::warn!(
                       correlation_id = %correlation_id,
                       "Usage update affected zero rows"
                   );
               }
               Ok(_) => {
                   tracing::debug!(
                       correlation_id = %correlation_id,
                       "Updated request log with usage data"
                   );
               }
               Err(e) => {
                   tracing::warn!(
                       correlation_id = %correlation_id,
                       error = %e,
                       "Failed to update request log with usage data"
                   );
               }
           }
       });
   }
   ```

3. Add tests for `update_usage` using in-memory SQLite. Add a `#[cfg(test)]` module at the bottom of `logging.rs`:
   - Test `update_usage_writes_tokens`: Create in-memory pool, run migrations, insert a row via `RequestLog::insert`, call `update_usage` with Some values, query the row and assert input_tokens, output_tokens, cost_sats are updated. Assert rows_affected == 1.
   - Test `update_usage_with_nulls`: Insert a row, call `update_usage` with all None values (marking stream completed but no usage). Assert rows_affected == 1 and columns are NULL.
   - Test `update_usage_no_matching_row`: Call `update_usage` with a non-existent correlation_id. Assert rows_affected == 0 (no error, just zero rows).

   For in-memory SQLite setup, use:
   ```rust
   let pool = SqlitePool::connect("sqlite::memory:").await.unwrap();
   sqlx::migrate!("./migrations").run(&pool).await.unwrap();
   ```
  </action>
  <verify>
Run `cargo test` -- all tests pass including the 3 new update_usage tests. Run `cargo clippy -- -D warnings` -- no warnings.
  </verify>
  <done>
`update_usage` function exists and writes input_tokens, output_tokens, cost_sats to an existing row by correlation_id. `spawn_usage_update` wraps it in fire-and-forget pattern with warn on zero rows and warn on error. Three tests verify: successful update with values, update with NULLs, and zero-row warning case.
  </done>
</task>

</tasks>

<verification>
1. `cargo test` -- all tests pass (existing + new), zero failures
2. `cargo clippy -- -D warnings` -- no warnings
3. `cargo build` -- compiles cleanly
4. Verify stream_options is NOT serialized when None: create a ChatCompletionRequest without stream_options, serialize to JSON, assert "stream_options" key is absent
5. Verify stream_options IS serialized after ensure_stream_options: create request, call ensure, serialize, assert `"stream_options":{"include_usage":true}` is present
</verification>

<success_criteria>
- StreamOptions struct and stream_options field added to types.rs with proper serde attributes
- ensure_stream_options merges rather than overwrites client values
- send_to_provider injects stream_options only for streaming requests (is_streaming == true)
- Non-streaming requests pass through completely unmodified
- update_usage and spawn_usage_update added to storage/logging.rs
- spawn_usage_update warns on zero rows_affected
- All existing tests pass unchanged (backward compatible)
- At least 6 new tests (3 for injection, 3 for DB update)
- cargo clippy clean
</success_criteria>

<output>
After completion, create `.planning/phases/08-stream-request-foundation/08-01-SUMMARY.md`
</output>
