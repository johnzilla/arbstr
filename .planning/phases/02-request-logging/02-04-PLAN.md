---
phase: 02-request-logging
plan: 04
type: execute
wave: 4
depends_on: ["02-02", "02-03"]
files_modified:
  - src/proxy/handlers.rs
autonomous: true

must_haves:
  truths:
    - "After a successful non-streaming request, a row appears in SQLite with all fields populated: timestamp, model, provider, input_tokens, output_tokens, cost_sats, latency_ms, success=true, correlation_id"
    - "Token counts in the log match the usage object from the provider response (prompt_tokens and completion_tokens)"
    - "Latency is measured as wall-clock milliseconds from handler start to response ready"
    - "Database write is fire-and-forget via spawn_log_write -- the response is returned BEFORE the write completes"
    - "Failed provider requests (non-2xx status) are logged with success=false, error_status, error_message, null tokens/cost"
    - "Pre-route rejections (NoProviders, NoPolicyMatch, BadRequest) are logged with provider=null, success=false, error_status, error_message"
    - "Streaming requests are logged with streaming=true; usage is extracted from the final SSE chunk if present"
    - "If database pool is None (DB not initialized), logging is silently skipped"
    - "Both arbstr-calculated cost (via actual_cost_sats) AND provider-reported cost are logged in separate columns"
    - "The TODO comment on line 120 is replaced with actual logging code"
  artifacts:
    - path: "src/proxy/handlers.rs"
      provides: "Complete request logging for all code paths in chat_completions handler"
      contains: "spawn_log_write"
  key_links:
    - from: "chat_completions"
      to: "spawn_log_write"
      via: "Fire-and-forget database write after response construction"
      pattern: "spawn_log_write"
    - from: "chat_completions"
      to: "actual_cost_sats"
      via: "Cost calculation from extracted token counts"
      pattern: "actual_cost_sats"
    - from: "chat_completions"
      to: "RequestId"
      via: "Extension extractor for correlation ID"
      pattern: "Extension.*RequestId"
---

<objective>
Integrate request logging into the chat_completions handler for all code paths: successful non-streaming, successful streaming, provider errors, and pre-route rejections.

Purpose: This plan wires together the storage infrastructure (02-01/02-02) and correlation ID extensions (02-03) to implement the core Phase 2 requirement: every completed request is logged to SQLite with accurate token counts, costs, and latency.

Output: The chat_completions handler logs every request outcome to SQLite via fire-and-forget writes.
</objective>

<execution_context>
@/home/john/.claude/get-shit-done/workflows/execute-plan.md
@/home/john/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-request-logging/02-CONTEXT.md
@.planning/phases/02-request-logging/02-RESEARCH.md
@.planning/phases/02-request-logging/02-02-SUMMARY.md
@.planning/phases/02-request-logging/02-03-SUMMARY.md
@src/proxy/handlers.rs
@src/proxy/server.rs
@src/proxy/types.rs
@src/storage/logging.rs
@src/router/selector.rs
@src/error.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Restructure chat_completions handler for comprehensive logging</name>
  <files>src/proxy/handlers.rs</files>
  <action>
    Rewrite the `chat_completions` handler in `src/proxy/handlers.rs` to log every request outcome. The handler must be restructured so that logging happens in ALL code paths (success, provider error, pre-route rejection).

    The key structural change: wrap the core logic in an inner function/closure that returns `Result`, then log the outcome regardless of success or failure before returning to the client.

    Here is the complete replacement for the `chat_completions` function. Replace the ENTIRE function body:

    ```rust
    /// Handle POST /v1/chat/completions
    pub async fn chat_completions(
        State(state): State<AppState>,
        Extension(request_id): Extension<RequestId>,
        headers: HeaderMap,
        Json(request): Json<ChatCompletionRequest>,
    ) -> Result<Response, Error> {
        let start = std::time::Instant::now();
        let correlation_id = request_id.0.to_string();
        let model = request.model.clone();
        let is_streaming = request.stream.unwrap_or(false);

        let policy_name = headers
            .get(ARBSTR_POLICY_HEADER)
            .and_then(|v| v.to_str().ok())
            .map(|s| s.to_string());

        let user_prompt = request.user_prompt();

        tracing::info!(
            model = %request.model,
            policy = ?policy_name,
            stream = ?request.stream,
            "Received chat completion request"
        );

        // Execute the core request logic, capturing the outcome for logging
        let result = execute_request(&state, &request, policy_name.as_deref(), user_prompt, is_streaming).await;

        // Log the outcome (fire-and-forget)
        let latency_ms = start.elapsed().as_millis() as i64;
        if let Some(pool) = &state.db {
            let log_entry = match &result {
                Ok(outcome) => RequestLog {
                    correlation_id: correlation_id.clone(),
                    timestamp: chrono::Utc::now().to_rfc3339(),
                    model: model.clone(),
                    provider: Some(outcome.provider_name.clone()),
                    policy: policy_name.clone(),
                    streaming: is_streaming,
                    input_tokens: outcome.input_tokens,
                    output_tokens: outcome.output_tokens,
                    cost_sats: outcome.cost_sats,
                    provider_cost_sats: outcome.provider_cost_sats,
                    latency_ms,
                    success: true,
                    error_status: None,
                    error_message: None,
                },
                Err(outcome_err) => RequestLog {
                    correlation_id: correlation_id.clone(),
                    timestamp: chrono::Utc::now().to_rfc3339(),
                    model: model.clone(),
                    provider: outcome_err.provider_name.clone(),
                    policy: policy_name.clone(),
                    streaming: is_streaming,
                    input_tokens: None,
                    output_tokens: None,
                    cost_sats: None,
                    provider_cost_sats: None,
                    latency_ms,
                    success: false,
                    error_status: Some(outcome_err.status_code),
                    error_message: Some(outcome_err.message.clone()),
                },
            };
            spawn_log_write(pool, log_entry);
        }

        // Convert outcome to HTTP response
        match result {
            Ok(outcome) => Ok(outcome.response),
            Err(outcome_err) => Err(outcome_err.error),
        }
    }
    ```

    Add these supporting types and the `execute_request` function ABOVE `chat_completions` (or below it, order doesn't matter in Rust, but before is cleaner):

    ```rust
    /// Outcome of a successful request, containing the response and metadata for logging.
    struct RequestOutcome {
        response: Response,
        provider_name: String,
        input_tokens: Option<u32>,
        output_tokens: Option<u32>,
        cost_sats: Option<f64>,
        provider_cost_sats: Option<f64>,
    }

    /// Outcome of a failed request, containing the error and metadata for logging.
    struct RequestError {
        error: Error,
        provider_name: Option<String>,
        status_code: u16,
        message: String,
    }

    /// Execute the core request logic (provider selection, forwarding, response handling).
    ///
    /// Returns Ok(RequestOutcome) on success or Err(RequestError) on any failure.
    /// This separation allows the caller to log both outcomes before returning.
    async fn execute_request(
        state: &AppState,
        request: &ChatCompletionRequest,
        policy_name: Option<&str>,
        user_prompt: Option<&str>,
        is_streaming: bool,
    ) -> std::result::Result<RequestOutcome, RequestError> {
        // Select provider
        let provider = state
            .router
            .select(&request.model, policy_name, user_prompt)
            .map_err(|e| {
                let (status_code, message) = match &e {
                    Error::NoProviders { .. } => (400u16, e.to_string()),
                    Error::NoPolicyMatch => (400, e.to_string()),
                    Error::BadRequest(_) => (400, e.to_string()),
                    _ => (500, e.to_string()),
                };
                RequestError {
                    error: e,
                    provider_name: None,
                    status_code,
                    message,
                }
            })?;

        tracing::info!(
            provider = %provider.name,
            url = %provider.url,
            output_rate = %provider.output_rate,
            "Selected provider"
        );

        // Build upstream URL
        let upstream_url = format!("{}/chat/completions", provider.url.trim_end_matches('/'));

        // Forward request to provider
        let mut upstream_request = state
            .http_client
            .post(&upstream_url)
            .header(header::CONTENT_TYPE, "application/json")
            .json(request);

        if let Some(api_key) = &provider.api_key {
            upstream_request =
                upstream_request.header(header::AUTHORIZATION, format!("Bearer {}", api_key));
        }

        let upstream_response = upstream_request.send().await.map_err(|e| {
            tracing::error!(error = %e, provider = %provider.name, "Failed to reach provider");
            RequestError {
                error: Error::Provider(format!(
                    "Failed to reach provider '{}': {}",
                    provider.name, e
                )),
                provider_name: Some(provider.name.clone()),
                status_code: 502,
                message: format!("Failed to reach provider: {}", e),
            }
        })?;

        let status = upstream_response.status();
        if !status.is_success() {
            let error_body = upstream_response.text().await.unwrap_or_default();
            tracing::error!(
                status = %status,
                provider = %provider.name,
                body = %error_body,
                "Provider returned error"
            );
            return Err(RequestError {
                error: Error::Provider(format!(
                    "Provider '{}' returned {}: {}",
                    provider.name, status, error_body
                )),
                provider_name: Some(provider.name.clone()),
                status_code: status.as_u16(),
                message: format!("Provider returned {}", status),
            });
        }

        if is_streaming {
            handle_streaming_response(upstream_response, &provider).await
        } else {
            handle_non_streaming_response(upstream_response, &provider).await
        }
    }
    ```

    Add the non-streaming handler:

    ```rust
    /// Handle a non-streaming provider response.
    ///
    /// Extracts the usage object for token counts and calculates cost.
    async fn handle_non_streaming_response(
        upstream_response: reqwest::Response,
        provider: &crate::router::SelectedProvider,
    ) -> std::result::Result<RequestOutcome, RequestError> {
        let mut response: serde_json::Value = upstream_response.json().await.map_err(|e| {
            tracing::error!(error = %e, "Failed to parse provider response");
            RequestError {
                error: Error::Provider(format!(
                    "Failed to parse response from '{}': {}",
                    provider.name, e
                )),
                provider_name: Some(provider.name.clone()),
                status_code: 502,
                message: format!("Failed to parse response: {}", e),
            }
        })?;

        // Extract usage for logging
        let usage = extract_usage(&response);
        let (input_tokens, output_tokens) = match usage {
            Some((input, output)) => (Some(input), Some(output)),
            None => (None, None),
        };

        // Calculate arbstr cost using config rates
        let cost_sats = match (input_tokens, output_tokens) {
            (Some(input), Some(output)) => Some(crate::router::actual_cost_sats(
                input,
                output,
                provider.input_rate,
                provider.output_rate,
                provider.base_fee,
            )),
            _ => None,
        };

        // Extract provider-reported cost (if present in response)
        let provider_cost_sats = response
            .get("usage")
            .and_then(|u| u.get("total_cost"))
            .and_then(|v| v.as_f64());

        // Add arbstr metadata to response
        if let Some(obj) = response.as_object_mut() {
            obj.insert(
                "arbstr_provider".to_string(),
                serde_json::Value::String(provider.name.clone()),
            );
        }

        let http_response = Response::builder()
            .status(StatusCode::OK)
            .header(header::CONTENT_TYPE, "application/json")
            .header("x-arbstr-provider", &provider.name)
            .body(Body::from(serde_json::to_vec(&response).unwrap()))
            .unwrap();

        Ok(RequestOutcome {
            response: http_response,
            provider_name: provider.name.clone(),
            input_tokens,
            output_tokens,
            cost_sats,
            provider_cost_sats,
        })
    }
    ```

    Add the streaming handler:

    ```rust
    /// Handle a streaming provider response.
    ///
    /// Passes SSE chunks through to the client while intercepting the final chunk
    /// for usage data (if present). Usage is captured without buffering the full stream.
    async fn handle_streaming_response(
        upstream_response: reqwest::Response,
        provider: &crate::router::SelectedProvider,
    ) -> std::result::Result<RequestOutcome, RequestError> {
        use std::sync::Arc;
        use tokio::sync::Mutex;

        let provider_name = provider.name.clone();
        let input_rate = provider.input_rate;
        let output_rate = provider.output_rate;
        let base_fee = provider.base_fee;

        // Shared state for capturing usage from the stream
        let captured_usage: Arc<Mutex<Option<(u32, u32)>>> = Arc::new(Mutex::new(None));
        let captured_usage_writer = captured_usage.clone();

        let stream = upstream_response.bytes_stream().map(move |chunk| {
            match chunk {
                Ok(ref bytes) => {
                    // Try to extract usage from SSE data lines in this chunk
                    if let Ok(text) = std::str::from_utf8(bytes) {
                        for line in text.lines() {
                            if let Some(data) = line.strip_prefix("data: ") {
                                if data != "[DONE]" {
                                    if let Ok(parsed) =
                                        serde_json::from_str::<serde_json::Value>(data)
                                    {
                                        if let Some(usage) =
                                            parsed.get("usage").filter(|u| !u.is_null())
                                        {
                                            if let (Some(input), Some(output)) = (
                                                usage
                                                    .get("prompt_tokens")
                                                    .and_then(|v| v.as_u64()),
                                                usage
                                                    .get("completion_tokens")
                                                    .and_then(|v| v.as_u64()),
                                            ) {
                                                if let Ok(mut guard) =
                                                    captured_usage_writer.try_lock()
                                                {
                                                    *guard =
                                                        Some((input as u32, output as u32));
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
                Err(ref e) => {
                    tracing::error!(error = %e, "Error streaming from provider");
                }
            }
            chunk.map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))
        });

        let body = Body::from_stream(stream);

        let http_response = Response::builder()
            .status(StatusCode::OK)
            .header(header::CONTENT_TYPE, "text/event-stream")
            .header(header::CACHE_CONTROL, "no-cache")
            .header("x-arbstr-provider", &provider_name)
            .body(body)
            .unwrap();

        // For streaming, we return the response immediately.
        // Usage data will be captured as chunks flow through.
        // NOTE: At this point, usage is likely not yet captured because the stream
        // hasn't been consumed. The logging for streaming responses happens
        // with whatever usage was captured. Since the stream is consumed by the
        // client asynchronously, we log with None tokens for now.
        // Full streaming usage tracking would require logging after stream completion,
        // which is a more complex pattern (wrapping the stream body to detect end).
        //
        // For Phase 2, log streaming requests with None tokens/cost if usage
        // is not immediately available. This matches the CONTEXT.md decision:
        // "if missing or incomplete, log with null token/cost fields"

        Ok(RequestOutcome {
            response: http_response,
            provider_name,
            input_tokens: None,
            output_tokens: None,
            cost_sats: None,
            provider_cost_sats: None,
        })
    }
    ```

    Add the usage extraction helper:

    ```rust
    /// Extract token usage from a provider response.
    ///
    /// Returns (prompt_tokens, completion_tokens) if the usage object is present
    /// and contains both fields. Returns None if usage is missing or incomplete.
    fn extract_usage(response: &serde_json::Value) -> Option<(u32, u32)> {
        let usage = response.get("usage")?;
        let input = usage.get("prompt_tokens")?.as_u64()? as u32;
        let output = usage.get("completion_tokens")?.as_u64()? as u32;
        Some((input, output))
    }
    ```

    Update the imports at the top of `handlers.rs`:

    ```rust
    use axum::{
        body::Body,
        extract::{Extension, State},
        http::{header, HeaderMap, StatusCode},
        response::{IntoResponse, Response},
        Json,
    };
    use futures::StreamExt;

    use super::server::{AppState, RequestId};
    use super::types::ChatCompletionRequest;
    use crate::error::Error;
    use crate::storage::logging::{RequestLog, spawn_log_write};
    ```

    Add `use chrono;` if not already imported (chrono is in Cargo.toml deps).

    IMPORTANT NOTES:
    - The `Extension(request_id): Extension<RequestId>` extractor is added to the `chat_completions` signature
    - The `execute_request` function returns a custom `Result` with `RequestOutcome`/`RequestError` so both paths can be logged
    - For streaming, usage is logged as None because the stream hasn't been consumed when the response is returned. The stream interceptor captures usage for chunks that have flowed through, but by the time we log, the response body is being sent to the client. This is acceptable per CONTEXT.md: "if missing or incomplete, log with null token/cost fields"
    - The `TODO: Log to database for cost tracking` comment on line 120 is removed because actual logging replaces it
    - Pre-route rejections (NoProviders, NoPolicyMatch, BadRequest) are caught by the `map_err` on `state.router.select()` and logged with provider=None
    - Provider errors (non-2xx status) are caught and logged with provider name and HTTP status
  </action>
  <verify>
    ```bash
    # Compiles cleanly
    cargo build 2>&1 | tail -10

    # All tests pass
    cargo test

    # No clippy warnings
    cargo clippy -- -D warnings

    # Verify spawn_log_write is used
    grep "spawn_log_write" src/proxy/handlers.rs

    # Verify actual_cost_sats is used
    grep "actual_cost_sats" src/proxy/handlers.rs

    # Verify Extension<RequestId> in handler signature
    grep "Extension.*RequestId" src/proxy/handlers.rs

    # Verify extract_usage function exists
    grep "fn extract_usage" src/proxy/handlers.rs

    # Verify TODO is removed
    ! grep "TODO.*Log to database" src/proxy/handlers.rs

    # Verify error paths log too
    grep "RequestError" src/proxy/handlers.rs
    ```
  </verify>
  <done>
    - `chat_completions` handler logs all request outcomes via `spawn_log_write`
    - Non-streaming: token usage extracted from response `usage` object
    - Streaming: usage interceptor in place; logged with None tokens for Phase 2
    - Failed provider requests logged with success=false, status code, error message
    - Pre-route rejections logged with provider=None, success=false
    - Fire-and-forget write pattern used (response returned before DB write)
    - If `state.db` is None, logging is silently skipped
    - `TODO: Log to database` comment removed
    - Cost calculated via `actual_cost_sats` when tokens are available
    - Both arbstr cost and provider cost logged in separate columns
    - `cargo build` succeeds, `cargo test` passes, `cargo clippy` clean
  </done>
</task>

<task type="auto">
  <name>Task 2: Add integration test for request logging</name>
  <files>src/proxy/handlers.rs</files>
  <action>
    Add a test module to `src/proxy/handlers.rs` (or verify the build with a basic test) to confirm the extract_usage helper works correctly:

    Add at the bottom of `src/proxy/handlers.rs`:

    ```rust
    #[cfg(test)]
    mod tests {
        use super::*;

        #[test]
        fn test_extract_usage_present() {
            let response = serde_json::json!({
                "id": "chatcmpl-123",
                "choices": [],
                "usage": {
                    "prompt_tokens": 100,
                    "completion_tokens": 200,
                    "total_tokens": 300
                }
            });
            let usage = extract_usage(&response);
            assert_eq!(usage, Some((100, 200)));
        }

        #[test]
        fn test_extract_usage_missing() {
            let response = serde_json::json!({
                "id": "chatcmpl-123",
                "choices": []
            });
            let usage = extract_usage(&response);
            assert_eq!(usage, None);
        }

        #[test]
        fn test_extract_usage_partial() {
            let response = serde_json::json!({
                "id": "chatcmpl-123",
                "choices": [],
                "usage": {
                    "prompt_tokens": 100
                }
            });
            let usage = extract_usage(&response);
            assert_eq!(usage, None);
        }

        #[test]
        fn test_extract_usage_null() {
            let response = serde_json::json!({
                "id": "chatcmpl-123",
                "choices": [],
                "usage": null
            });
            let usage = extract_usage(&response);
            assert_eq!(usage, None);
        }
    }
    ```

    After adding tests, run:
    ```bash
    cargo test
    cargo clippy -- -D warnings
    ```
  </action>
  <verify>
    ```bash
    # All tests pass including new ones
    cargo test

    # Specific new tests pass
    cargo test test_extract_usage

    # No clippy warnings
    cargo clippy -- -D warnings
    ```
  </verify>
  <done>
    - 4 tests for `extract_usage` added and passing
    - Tests cover: present usage, missing usage, partial usage, null usage
    - All existing tests still pass
    - `cargo clippy` clean
  </done>
</task>

</tasks>

<verification>
```bash
# Full build succeeds
cargo build 2>&1 | tail -10

# All tests pass (existing + new extract_usage tests)
cargo test

# No clippy warnings
cargo clippy -- -D warnings

# Handler uses fire-and-forget logging
grep "spawn_log_write" src/proxy/handlers.rs

# Handler extracts correlation ID from extension
grep "Extension.*RequestId" src/proxy/handlers.rs

# Handler extracts usage from response
grep "extract_usage" src/proxy/handlers.rs

# Handler calculates cost
grep "actual_cost_sats" src/proxy/handlers.rs

# No remaining TODO for database logging
! grep "TODO.*Log to database" src/proxy/handlers.rs

# Error paths are logged
grep -c "RequestError" src/proxy/handlers.rs
```
</verification>

<success_criteria>
- Every chat_completions request is logged: success, provider error, and pre-route rejection
- Non-streaming: token counts extracted from usage object, cost calculated
- Streaming: logged with None tokens (usage interceptor in place for future enhancement)
- Latency measured from handler start to response ready
- Fire-and-forget write via spawn_log_write (response not blocked)
- If DB is None, logging silently skipped
- TODO comment replaced with actual logging
- Both arbstr cost and provider cost tracked
- extract_usage unit tests pass
- No regressions in existing tests
</success_criteria>

<output>
After completion, create `.planning/phases/02-request-logging/02-04-SUMMARY.md`
</output>
