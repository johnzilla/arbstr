---
phase: 02-request-logging
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - Cargo.toml
  - build.rs
  - migrations/20260203000000_initial_schema.sql
  - src/storage/mod.rs
  - src/storage/logging.rs
autonomous: true

must_haves:
  truths:
    - "Database file is auto-created on first startup without manual setup"
    - "Migration applies automatically on startup, creating requests and token_ratios tables"
    - "RequestLog can be inserted into the database with all required fields"
    - "Fire-and-forget logging via spawn_log_write does not block callers"
    - "cargo build succeeds with sqlx migrate feature enabled"
  artifacts:
    - path: "migrations/20260203000000_initial_schema.sql"
      provides: "Database schema for requests and token_ratios tables"
      contains: "CREATE TABLE"
    - path: "src/storage/mod.rs"
      provides: "Pool initialization function and module re-exports"
      contains: "init_pool"
    - path: "src/storage/logging.rs"
      provides: "RequestLog struct and insert method"
      contains: "RequestLog"
    - path: "build.rs"
      provides: "Migration recompilation trigger"
      contains: "rerun-if-changed=migrations"
  key_links:
    - from: "init_pool"
      to: "sqlx::migrate!()"
      via: "Migrations applied during pool initialization"
      pattern: "migrate!.*run"
    - from: "spawn_log_write"
      to: "RequestLog::insert"
      via: "Fire-and-forget tokio::spawn with pool clone"
      pattern: "tokio::spawn"
---

<objective>
Create the SQLite storage infrastructure: migration, storage module, pool initialization, and RequestLog with fire-and-forget insert.

Purpose: Phase 2 requires persistent request logging to SQLite. Before any handler can log, the schema must be applied, and the RequestLog struct and insert function must be available. This plan builds the storage module; the next plan (02-02) integrates it into AppState and lib.rs.

Output: Working storage module with pool init, migration, RequestLog struct, and spawn_log_write. Not yet wired into the server.
</objective>

<execution_context>
@/home/john/.claude/get-shit-done/workflows/execute-plan.md
@/home/john/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-request-logging/02-CONTEXT.md
@.planning/phases/02-request-logging/02-RESEARCH.md
@src/error.rs
@src/lib.rs
@Cargo.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add migrate feature to sqlx in Cargo.toml</name>
  <files>Cargo.toml</files>
  <action>
    In Cargo.toml, update the sqlx dependency to include the `migrate` feature:

    Change:
    ```toml
    sqlx = { version = "0.8", features = ["runtime-tokio", "sqlite"] }
    ```

    To:
    ```toml
    sqlx = { version = "0.8", features = ["runtime-tokio", "sqlite", "migrate"] }
    ```

    This enables the `sqlx::migrate!()` proc macro for embedded migrations.
  </action>
  <verify>
    ```bash
    grep 'sqlx.*migrate' Cargo.toml
    ```
  </verify>
  <done>
    sqlx dependency in Cargo.toml includes the `migrate` feature.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create build.rs and migration SQL</name>
  <files>build.rs, migrations/20260203000000_initial_schema.sql</files>
  <action>
    1. Create `build.rs` in the project root (same level as Cargo.toml) with the following content:

    ```rust
    fn main() {
        println!("cargo:rerun-if-changed=migrations");
    }
    ```

    This ensures that when migration SQL files change, cargo rebuilds the binary (because the `migrate!()` macro embeds migration SQL at compile time).

    2. Create the directory `migrations/` in the project root, then create the file `migrations/20260203000000_initial_schema.sql` with the following content:

    ```sql
    -- Request log for cost tracking and observability
    CREATE TABLE IF NOT EXISTS requests (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        correlation_id TEXT NOT NULL,
        timestamp TEXT NOT NULL,
        model TEXT NOT NULL,
        provider TEXT,
        policy TEXT,
        streaming BOOLEAN NOT NULL DEFAULT FALSE,
        input_tokens INTEGER,
        output_tokens INTEGER,
        cost_sats REAL,
        provider_cost_sats REAL,
        latency_ms INTEGER NOT NULL,
        success BOOLEAN NOT NULL,
        error_status INTEGER,
        error_message TEXT
    );

    CREATE INDEX IF NOT EXISTS idx_requests_correlation_id ON requests(correlation_id);
    CREATE INDEX IF NOT EXISTS idx_requests_timestamp ON requests(timestamp);

    -- Learned input/output ratios per policy (populated in future phases)
    CREATE TABLE IF NOT EXISTS token_ratios (
        policy TEXT PRIMARY KEY,
        avg_ratio REAL NOT NULL,
        sample_count INTEGER NOT NULL DEFAULT 0
    );
    ```

    Column type rationale (from CONTEXT.md decisions):
    - `id`: INTEGER PRIMARY KEY AUTOINCREMENT -- auto-increment
    - `correlation_id`: TEXT NOT NULL, indexed -- UUID as string
    - `timestamp`: TEXT -- ISO 8601 string (SQLite standard for datetimes)
    - `model`: TEXT NOT NULL -- always known from request
    - `provider`: TEXT nullable -- null for pre-route rejections
    - `cost_sats`: REAL -- f64 for sub-satoshi precision
    - `provider_cost_sats`: REAL nullable -- provider-reported cost
    - `streaming`: BOOLEAN NOT NULL -- per CONTEXT.md
    - `error_status`: INTEGER nullable -- HTTP status code for errors
    - `error_message`: TEXT nullable -- short description for errors
    - `token_ratios` table: created now but populated in future phases
  </action>
  <verify>
    ```bash
    cat build.rs
    cat migrations/20260203000000_initial_schema.sql
    ```
  </verify>
  <done>
    build.rs exists with `cargo:rerun-if-changed=migrations`. Migration SQL file exists with requests table (all columns), indexes on correlation_id and timestamp, and token_ratios table.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create storage module with pool init and RequestLog</name>
  <files>src/storage/mod.rs, src/storage/logging.rs</files>
  <action>
    Create the directory `src/storage/` and both files:

    **src/storage/mod.rs:**

    ```rust
    //! SQLite storage for request logging and metrics.

    pub mod logging;

    pub use logging::RequestLog;

    use sqlx::sqlite::{SqliteConnectOptions, SqliteJournalMode, SqlitePoolOptions, SqliteSynchronous};
    use sqlx::SqlitePool;
    use std::str::FromStr;

    /// Initialize the SQLite connection pool and run migrations.
    ///
    /// The database file is created automatically if it doesn't exist.
    /// WAL journal mode is used for concurrent read/write performance.
    pub async fn init_pool(db_path: &str) -> Result<SqlitePool, sqlx::Error> {
        let opts = SqliteConnectOptions::from_str(&format!("sqlite://{}", db_path))?
            .journal_mode(SqliteJournalMode::Wal)
            .synchronous(SqliteSynchronous::Normal)
            .create_if_missing(true);

        let pool = SqlitePoolOptions::new()
            .max_connections(5)
            .connect_with(opts)
            .await?;

        // Apply embedded migrations
        sqlx::migrate!().run(&pool).await?;

        Ok(pool)
    }
    ```

    **src/storage/logging.rs:**

    ```rust
    //! Request logging data types and database operations.

    use sqlx::SqlitePool;

    /// A completed request log entry ready for database insertion.
    ///
    /// All fields are owned types to satisfy `tokio::spawn` `'static` requirement.
    pub struct RequestLog {
        pub correlation_id: String,
        pub timestamp: String,
        pub model: String,
        pub provider: Option<String>,
        pub policy: Option<String>,
        pub streaming: bool,
        pub input_tokens: Option<u32>,
        pub output_tokens: Option<u32>,
        pub cost_sats: Option<f64>,
        pub provider_cost_sats: Option<f64>,
        pub latency_ms: i64,
        pub success: bool,
        pub error_status: Option<u16>,
        pub error_message: Option<String>,
    }

    impl RequestLog {
        /// Insert this log entry into the database.
        pub async fn insert(&self, pool: &SqlitePool) -> Result<(), sqlx::Error> {
            sqlx::query(
                "INSERT INTO requests (
                    correlation_id, timestamp, model, provider, policy,
                    streaming, input_tokens, output_tokens,
                    cost_sats, provider_cost_sats,
                    latency_ms, success, error_status, error_message
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)"
            )
            .bind(&self.correlation_id)
            .bind(&self.timestamp)
            .bind(&self.model)
            .bind(&self.provider)
            .bind(&self.policy)
            .bind(self.streaming)
            .bind(self.input_tokens.map(|v| v as i64))
            .bind(self.output_tokens.map(|v| v as i64))
            .bind(self.cost_sats)
            .bind(self.provider_cost_sats)
            .bind(self.latency_ms)
            .bind(self.success)
            .bind(self.error_status.map(|v| v as i32))
            .bind(self.error_message.as_deref())
            .execute(pool)
            .await?;
            Ok(())
        }
    }

    /// Spawn a fire-and-forget database write.
    ///
    /// If the write fails, a warning is logged but the error is not propagated.
    /// This function is designed to be called after the response is ready,
    /// so database failures never block the client.
    pub fn spawn_log_write(pool: &SqlitePool, log: RequestLog) {
        let pool = pool.clone();
        tokio::spawn(async move {
            if let Err(e) = log.insert(&pool).await {
                tracing::warn!(
                    correlation_id = %log.correlation_id,
                    error = %e,
                    "Failed to write request log to database"
                );
            }
        });
    }
    ```

    Key design decisions:
    - `create_if_missing(true)` is critical -- without it, first-time startup fails
    - WAL + Normal synchronous is the recommended configuration for a logging workload
    - `max_connections(5)` is sufficient for a single-user tool
    - `sqlx::migrate!()` reads from the `migrations/` directory at compile time
    - All RequestLog fields are owned (`String`, not `&str`) so the struct is `'static` for `tokio::spawn`
    - `spawn_log_write` clones the pool (cheap, Arc-based) and moves owned data
    - Uses `sqlx::query()` runtime function, NOT `sqlx::query!()` compile-time macro

    Note: `sqlx::migrate!().run()` returns `Result<(), MigrateError>`. `MigrateError` implements `Into<sqlx::Error>`, so the `?` operator converts it. However, if this doesn't compile, the signature may need to return `Result<SqlitePool, Box<dyn std::error::Error>>` or use explicit mapping. Test compilation.
  </action>
  <verify>
    ```bash
    cat src/storage/mod.rs
    cat src/storage/logging.rs
    ```
  </verify>
  <done>
    - `src/storage/mod.rs` exists with `init_pool` function that creates a WAL-mode SQLite pool with create_if_missing(true) and runs embedded migrations
    - `src/storage/logging.rs` exists with `RequestLog` struct (all 14 fields, all owned types), `insert()` method using `sqlx::query()` with `?` bind parameters, and `spawn_log_write()` fire-and-forget function
  </done>
</task>

</tasks>

<verification>
```bash
# Migration file exists with correct tables
grep "CREATE TABLE" migrations/20260203000000_initial_schema.sql

# Storage module exists with init_pool
grep "pub async fn init_pool" src/storage/mod.rs

# RequestLog struct exists with all fields
grep -c "pub " src/storage/logging.rs

# spawn_log_write function exists
grep "pub fn spawn_log_write" src/storage/logging.rs

# build.rs exists
cat build.rs

# Cargo.toml has migrate feature
grep 'sqlx.*migrate' Cargo.toml
```
</verification>

<success_criteria>
- Migration SQL creates `requests` and `token_ratios` tables with correct columns
- `init_pool` creates a WAL-mode SQLite pool with `create_if_missing(true)` and runs migrations
- `RequestLog` has all 14 fields (all owned types) and an `insert` method
- `spawn_log_write` provides fire-and-forget write capability
- `build.rs` triggers recompilation on migration changes
- `Cargo.toml` includes sqlx `migrate` feature
</success_criteria>

<output>
After completion, create `.planning/phases/02-request-logging/02-01-SUMMARY.md`
</output>
