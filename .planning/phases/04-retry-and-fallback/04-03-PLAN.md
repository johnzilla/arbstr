---
phase: 04-retry-and-fallback
plan: 03
type: execute
wave: 2
depends_on: ["04-01", "04-02"]
files_modified:
  - src/proxy/handlers.rs
autonomous: true

must_haves:
  truths:
    - "Non-streaming requests that get 5xx from primary are retried with backoff and fall back to alternate provider"
    - "Streaming requests skip retry entirely and fail fast (existing behavior preserved)"
    - "x-arbstr-retries header shows attempt count per provider on responses that involved retries"
    - "x-arbstr-provider header shows the actual provider that handled the request (including fallback)"
    - "The Idempotency-Key header is sent to upstream providers with the correlation ID value"
    - "A 30-second total deadline wraps the entire retry+fallback chain"
    - "Timeout returns 504 Gateway Timeout with OpenAI-compatible error JSON"
    - "Only one row logged per request in SQLite, with the actual provider that handled it"
    - "Error responses remain valid OpenAI-compatible JSON through all retry/fallback/timeout paths"
  artifacts:
    - path: "src/proxy/handlers.rs"
      provides: "Retry-integrated chat_completions handler with send_to_provider extraction"
      contains: "retry_with_fallback"
      contains: "send_to_provider"
      contains: "Idempotency-Key"
      contains: "timeout_at"
  key_links:
    - from: "chat_completions"
      to: "retry_with_fallback"
      via: "wraps non-streaming request path in retry loop"
      pattern: "retry_with_fallback"
    - from: "chat_completions"
      to: "select_candidates"
      via: "gets ordered candidate list instead of single provider"
      pattern: "select_candidates"
    - from: "chat_completions"
      to: "format_retries_header"
      via: "builds x-arbstr-retries header from attempt history"
      pattern: "format_retries_header"
    - from: "chat_completions"
      to: "timeout_at"
      via: "30-second deadline wrapping retry+fallback"
      pattern: "timeout_at"
    - from: "send_to_provider"
      to: "Idempotency-Key"
      via: "adds correlation ID as idempotency key to upstream request"
      pattern: "Idempotency-Key"
---

<objective>
Wire the retry module and router candidates into the chat_completions handler. Extract a `send_to_provider` function, use `retry_with_fallback` for non-streaming requests, add the `Idempotency-Key` header, attach `x-arbstr-retries` on responses, and wrap with a 30-second deadline.

Purpose: This is the integration plan that connects the independently-built Router candidates (Plan 01) and retry module (Plan 02) into the live request path.
Output: Modified `handlers.rs` with retry-integrated request flow.
</objective>

<execution_context>
@/home/john/.claude/get-shit-done/workflows/execute-plan.md
@/home/john/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-retry-and-fallback/04-CONTEXT.md
@.planning/phases/04-retry-and-fallback/04-RESEARCH.md
@.planning/phases/04-retry-and-fallback/04-01-SUMMARY.md
@.planning/phases/04-retry-and-fallback/04-02-SUMMARY.md
@src/proxy/handlers.rs
@src/proxy/retry.rs
@src/proxy/server.rs
@src/router/selector.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extract send_to_provider and implement HasStatusCode</name>
  <files>src/proxy/handlers.rs</files>
  <action>
**Make types pub(crate):**
Change `struct RequestOutcome` and `struct RequestError` to `pub(crate) struct RequestOutcome` and `pub(crate) struct RequestError`. Make their fields `pub(crate)` as well.

**Implement HasStatusCode for RequestError:**
```rust
impl super::retry::HasStatusCode for RequestError {
    fn status_code(&self) -> u16 {
        self.status_code
    }
}
```

**Extract `send_to_provider` function:**
Extract the provider-calling logic from `execute_request` into a standalone async function:

```rust
async fn send_to_provider(
    state: &AppState,
    request: &ChatCompletionRequest,
    provider: &crate::router::SelectedProvider,
    correlation_id: &str,
    is_streaming: bool,
) -> std::result::Result<RequestOutcome, RequestError>
```

This function does:
1. Build upstream URL from provider
2. Build reqwest request with Content-Type, Authorization (if api_key), and JSON body
3. Add `Idempotency-Key` header with `correlation_id` value (IETF standard for retry idempotency)
4. Send request via `state.http_client`
5. On reqwest error: return `RequestError` with status 502 (network-level errors are treated as retryable 502)
6. On non-success HTTP status: return `RequestError` with the actual status code from the provider
7. On success: delegate to `handle_non_streaming_response` or `handle_streaming_response`

This is essentially the body of the current `execute_request` after provider selection, extracted into a reusable function. The key addition is the `Idempotency-Key` header.

**Modify `execute_request` to use `send_to_provider`:**
Simplify `execute_request` to:
1. Select provider via `state.router.select()` (unchanged for now -- this function is still used by the streaming path)
2. Log selected provider
3. Call `send_to_provider(state, request, &provider, correlation_id, is_streaming)`

Wait -- `execute_request` does not currently take `correlation_id`. For the refactoring in Task 2, we need it. Add `correlation_id: &str` parameter to `execute_request`. Update the call site in `chat_completions` to pass it.
  </action>
  <verify>
Run `cargo test` -- all existing tests pass (refactoring preserves behavior).
Run `cargo clippy -- -D warnings` -- clean.
  </verify>
  <done>
`send_to_provider` extracted as reusable async function. `RequestOutcome` and `RequestError` are `pub(crate)`. `HasStatusCode` implemented for `RequestError`. `Idempotency-Key` header added to upstream requests. All existing tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire retry_with_fallback into chat_completions for non-streaming</name>
  <files>src/proxy/handlers.rs</files>
  <action>
**Add new imports at top of handlers.rs:**
```rust
use tokio::time::{timeout_at, Instant, Duration};
use super::retry::{retry_with_fallback, format_retries_header, CandidateInfo};
```

**Add x-arbstr-retries header constant:**
```rust
pub const ARBSTR_RETRIES_HEADER: &str = "x-arbstr-retries";
```

**Add total timeout constant:**
```rust
const RETRY_TIMEOUT: Duration = Duration::from_secs(30);
```

**Modify `chat_completions` handler:**

Split the request flow into two paths:

**Non-streaming path (new retry-integrated flow):**
1. Call `state.router.select_candidates(&request.model, policy_name.as_deref(), user_prompt)` to get ordered candidate list
2. If select_candidates fails, handle as before (map to RequestError for logging, then return error response)
3. Build `Vec<CandidateInfo>` from candidates (just the names)
4. Keep the `Vec<SelectedProvider>` for use in the closure
5. Set up the deadline: `let deadline = Instant::now() + RETRY_TIMEOUT;`
6. Call `timeout_at(deadline, retry_with_fallback(&candidate_infos, |info| { ... }))`:
   - The closure finds the matching `SelectedProvider` by name from the candidates vec
   - Calls `send_to_provider(state, &request, provider, &correlation_id, false)`
7. Handle the timeout_at result:
   - `Err(_elapsed)` -> Return 504 Gateway Timeout with OpenAI-compatible error JSON. Include x-arbstr-request-id and x-arbstr-retries (if any attempts were recorded before timeout -- note: timeout cancels the future so we won't have the attempts vec. Return a generic "2/primary-name" or just omit x-arbstr-retries on pure timeout).
   - `Ok(retry_outcome)` -> Process retry_outcome.result (Ok or Err) and retry_outcome.attempts

8. For the retry_outcome:
   - Compute latency_ms from start
   - Log to SQLite using the final result (one row only). The provider field comes from the successful outcome's `provider_name` or the last error's `provider_name`.
   - Build response: attach standard arbstr headers (request-id, latency, provider, cost)
   - If `retry_outcome.attempts` is non-empty, call `format_retries_header(&retry_outcome.attempts)` and add `x-arbstr-retries` header to the response

**Streaming path (unchanged):**
Keep existing behavior exactly: call `execute_request` (which calls `send_to_provider` internally), log, attach headers. No retry.

**Timeout edge case:**
When `timeout_at` fires, we lose access to the retry_outcome (future is cancelled). Handle this by returning a 504 error response:
```rust
let timeout_error = Error::Provider("Request timed out after 30 seconds (retry budget exhausted)".to_string());
let mut error_response = timeout_error.into_response();
attach_arbstr_headers(&mut error_response, &correlation_id, latency_ms, None, None, false);
```
Log the timeout as a failed request with status 504.

**Important details:**
- The closure passed to `retry_with_fallback` needs to find the full `SelectedProvider` (with url, api_key, rates) from the `CandidateInfo` name. Store the candidates in a variable the closure can reference. Use an index-based approach or find-by-name in the candidates vec.
- Non-retryable errors (4xx) from the primary still skip fallback -- this is handled by `retry_with_fallback` already.
- `x-arbstr-provider` header already exists and is set by `attach_arbstr_headers`. The provider_name in RequestOutcome already reflects the actual provider (primary or fallback).
- Streaming detection happens before the path split: `let is_streaming = request.stream.unwrap_or(false);`
  </action>
  <verify>
Run `cargo build` -- compiles without errors.
Run `cargo test` -- all existing tests pass.
Run `cargo clippy -- -D warnings` -- clean.
Run `cargo run -- serve --mock` and test with curl:
  - `curl -X POST http://127.0.0.1:8080/v1/chat/completions -H "Content-Type: application/json" -d '{"model":"gpt-4o","messages":[{"role":"user","content":"hello"}]}' -v` -- should see response with arbstr headers, no x-arbstr-retries (no retries on success).
  </verify>
  <done>
Non-streaming requests go through `retry_with_fallback` with 30-second deadline. Streaming requests bypass retry. x-arbstr-retries header appears on responses that involved retries. Idempotency-Key sent to upstream. Timeout returns 504. One log row per request with actual provider. All existing tests pass. Mock server responds normally (no retries triggered).
  </done>
</task>

</tasks>

<verification>
- `cargo test` -- all tests pass
- `cargo clippy -- -D warnings` -- clean
- `cargo build --release` -- compiles
- `cargo run -- serve --mock` -- starts and handles requests
- Manual curl test against mock server returns 200 with arbstr headers
</verification>

<success_criteria>
- Non-streaming 5xx errors trigger up to 2 retries with backoff, then one fallback attempt
- Streaming requests are not retried (existing behavior preserved)
- x-arbstr-retries header shows "2/provider-alpha, 1/provider-beta" format on retried responses
- x-arbstr-provider shows actual provider (fallback if primary failed)
- Idempotency-Key header sent to upstream providers
- 30-second timeout returns 504 Gateway Timeout
- All error responses are OpenAI-compatible JSON
- Only one SQLite row logged per request
- All existing tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/04-retry-and-fallback/04-03-SUMMARY.md`
</output>
