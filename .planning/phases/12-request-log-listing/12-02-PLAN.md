---
phase: 12-request-log-listing
plan: 02
type: execute
wave: 2
depends_on: ["12-01"]
files_modified:
  - tests/logs.rs
autonomous: true

must_haves:
  truths:
    - "Integration tests verify paginated listing returns correct data array, page, per_page, total, total_pages, since, until"
    - "Integration tests verify model, provider, success, and streaming filters narrow results correctly"
    - "Integration tests verify sort by timestamp, cost_sats, latency_ms in both asc and desc order"
    - "Integration tests verify error cases: 404 for non-existent model/provider, 400 for invalid sort field, 200 for out-of-range page"
    - "Integration tests verify nested response structure: tokens, cost, timing, error sections"
  artifacts:
    - path: "tests/logs.rs"
      provides: "Integration tests covering all /v1/requests endpoint behaviors"
      min_lines: 200
  key_links:
    - from: "tests/logs.rs"
      to: "/v1/requests"
      via: "tower::ServiceExt::oneshot HTTP requests"
      pattern: "get.*app.*v1/requests"
---

<objective>
Add integration tests for the GET /v1/requests endpoint covering pagination, filtering, sorting, error handling, and response structure.

Purpose: Verify all three phase success criteria (LOG-01, LOG-02, LOG-03) are met with automated tests matching the tower::oneshot pattern from Phase 11.
Output: Comprehensive integration test suite for /v1/requests.
</objective>

<execution_context>
@/home/john/.claude/get-shit-done/workflows/execute-plan.md
@/home/john/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-request-log-listing/12-CONTEXT.md
@.planning/phases/12-request-log-listing/12-RESEARCH.md
@.planning/phases/12-request-log-listing/12-01-SUMMARY.md
@.planning/phases/11-aggregate-stats-and-filtering/11-02-SUMMARY.md

Key patterns from Phase 11 tests (tests/stats.rs):
- setup_test_app() creates in-memory SQLite + axum Router (reuse or duplicate this pattern)
- seed_request() inserts test rows with sequential correlation IDs
- get() helper for oneshot HTTP requests returning (StatusCode, Value)
- rfc3339z() for URL-safe timestamp formatting
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integration tests for /v1/requests endpoint</name>
  <files>tests/logs.rs</files>
  <action>
Create `tests/logs.rs` following the exact same setup pattern as `tests/stats.rs`. Duplicate the helper functions (setup_test_app, seed_request, parse_response, get, rfc3339z, test_config) -- they are small and test isolation is more important than DRY in integration tests. Use the same CORRELATION_COUNTER pattern for unique IDs.

Seed data design: Create a `seed_logs_data()` function that inserts records designed for testing pagination, filtering, and sorting:
- 5 recent records (within last 24h) to test pagination with per_page=2:
  1. gpt-4o / alpha / success=true / streaming=false / cost_sats=10.0 / latency_ms=100 / input_tokens=100 / output_tokens=200
  2. gpt-4o / alpha / success=true / streaming=true / cost_sats=20.0 / latency_ms=200 / input_tokens=150 / output_tokens=300 / stream_duration_ms=500
  3. claude-3.5-sonnet / alpha / success=true / streaming=false / cost_sats=30.0 / latency_ms=300 / input_tokens=200 / output_tokens=400
  4. gpt-4o / beta / success=false / streaming=false / cost_sats=None / latency_ms=500 / input_tokens=None / output_tokens=None / error_status=502 / error_message="Provider returned 502"
  5. gpt-4o-mini / beta / success=true / streaming=false / cost_sats=5.0 / latency_ms=50 / input_tokens=50 / output_tokens=100
- 1 old record (8 days ago): gpt-4o / alpha / success=true / streaming=false / cost_sats=8.0 / latency_ms=120

Update seed_request to also accept optional `stream_duration_ms`, `error_status`, and `error_message` params so we can seed error records and streaming duration. This means the INSERT statement needs to include those columns.

Write the following tests:

**Pagination (LOG-01):**
1. `test_logs_default_page` -- GET /v1/requests with no params. Assert: status 200, data is array, page=1, per_page=20, total=5 (default last_7d excludes old), total_pages=1, since and until are strings.
2. `test_logs_custom_page_size` -- GET /v1/requests?per_page=2. Assert: data.len()=2, per_page=2, total=5, total_pages=3.
3. `test_logs_page_2` -- GET /v1/requests?per_page=2&page=2. Assert: data.len()=2, page=2.
4. `test_logs_out_of_range_page` -- GET /v1/requests?page=999. Assert: status 200, data is empty array, page=999, total=5.
5. `test_logs_per_page_clamped_to_100` -- GET /v1/requests?per_page=500. Assert: per_page=100 in response.

**Filtering (LOG-02):**
6. `test_logs_filter_by_model` -- GET /v1/requests?model=gpt-4o&range=last_30d. Assert: all records in data have model "gpt-4o" (including old record). total should be 4.
7. `test_logs_filter_by_provider` -- GET /v1/requests?provider=beta. Assert: total=2, all records have provider "beta".
8. `test_logs_filter_by_success` -- GET /v1/requests?success=false. Assert: total=1, the failed record.
9. `test_logs_filter_by_streaming` -- GET /v1/requests?streaming=true. Assert: total=1, the streaming record.
10. `test_logs_combined_filters` -- GET /v1/requests?model=gpt-4o&provider=alpha. Assert: total=2 (records 1 and 2, both gpt-4o from alpha in recent).
11. `test_logs_filter_nonexistent_model_404` -- GET /v1/requests?model=nonexistent. Assert: status 404.
12. `test_logs_filter_nonexistent_provider_404` -- GET /v1/requests?provider=nonexistent. Assert: status 404.
13. `test_logs_time_range_last_30d` -- GET /v1/requests?range=last_30d. Assert: total=6 (includes old record).

**Sorting (LOG-03):**
14. `test_logs_sort_by_cost_asc` -- GET /v1/requests?sort=cost_sats&order=asc. Assert: status 200. First record has lowest cost (or null -- null costs sort first/last depending on SQLite default, assert the order is consistent).
15. `test_logs_sort_by_latency_desc` -- GET /v1/requests?sort=latency_ms&order=desc. Assert: first record has highest latency_ms (500).
16. `test_logs_invalid_sort_field_400` -- GET /v1/requests?sort=invalid. Assert: status 400, error message contains "Valid options".
17. `test_logs_invalid_sort_order_400` -- GET /v1/requests?sort=timestamp&order=sideways. Assert: status 400.

**Response structure:**
18. `test_logs_response_structure` -- GET /v1/requests. Pick first record and assert nested structure: data[0] has "tokens" object with "input"/"output", "cost" with "sats", "timing" with "latency_ms"/"stream_duration_ms". Assert "id" is integer, "timestamp" is string, "model" is string, "success" is boolean.
19. `test_logs_error_section_present_on_failure` -- Seed data, GET /v1/requests?success=false. Assert: the failed record has "error" section with "status" and "message" fields.
20. `test_logs_error_section_absent_on_success` -- GET /v1/requests?success=true&per_page=1. Assert: the successful record does NOT have "error" key (skip_serializing_if works).

Run `cargo test` after writing all tests. Fix any compilation errors or test failures. Then run `cargo fmt` and `cargo clippy -- -D warnings`.
  </action>
  <verify>
`cargo test` -- all tests pass (both new logs tests and existing stats tests). `cargo clippy -- -D warnings` clean. `cargo fmt --check` clean.
  </verify>
  <done>
20 integration tests covering all /v1/requests behaviors: 5 pagination tests (default, custom page size, page 2, out-of-range, clamping), 8 filter tests (model, provider, success, streaming, combined, 404s, time range), 4 sort tests (cost asc, latency desc, invalid field 400, invalid order 400), 3 structure tests (nested sections, error present on failure, error absent on success). All phase success criteria (LOG-01, LOG-02, LOG-03) verified by automated tests.
  </done>
</task>

<task type="auto">
  <name>Task 2: Smoke test and fix any issues</name>
  <files>tests/logs.rs</files>
  <action>
Run the full test suite and address any issues:

1. Run `cargo test` -- if any test fails, diagnose and fix. Common issues from Phase 11 experience:
   - COALESCE/TOTAL type mismatches on empty results -- use 0.0 not 0 for float columns
   - URL encoding of + in RFC 3339 timestamps -- use rfc3339z() helper
   - Boolean param deserialization -- ensure Option<bool> works with serde_urlencoded

2. Run `cargo fmt` to format all code.

3. Run `cargo clippy -- -D warnings` to catch any lint issues.

4. If any fixes were needed in the implementation (src/ files), note them as deviations.
  </action>
  <verify>
`cargo test` -- all tests pass (0 failures). `cargo clippy -- -D warnings` clean. `cargo fmt --check` clean.
  </verify>
  <done>
Full test suite green. No clippy warnings. Code formatted. Any auto-fixes from implementation bugs documented as deviations.
  </done>
</task>

</tasks>

<verification>
1. `cargo test` -- all tests pass including both stats and logs integration tests
2. `cargo clippy -- -D warnings` -- clean
3. `cargo fmt --check` -- clean
4. Phase success criteria verified by specific tests:
   - SC1 (LOG-01 pagination): test_logs_default_page, test_logs_custom_page_size, test_logs_page_2, test_logs_out_of_range_page
   - SC2 (LOG-02 filtering): test_logs_filter_by_model, test_logs_filter_by_provider, test_logs_filter_by_success, test_logs_filter_by_streaming
   - SC3 (LOG-03 sorting): test_logs_sort_by_cost_asc, test_logs_sort_by_latency_desc, test_logs_invalid_sort_field_400
</verification>

<success_criteria>
- 20 integration tests all passing
- Pagination, filtering, sorting, error handling, and response structure all covered
- No regressions in existing test suite
- Clean clippy and fmt
</success_criteria>

<output>
After completion, create `.planning/phases/12-request-log-listing/12-02-SUMMARY.md`
</output>
